{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  <span style=\"font-family: Arial; font-weight:bold;font-size:1.5em;color:#35c337\">Natural Language Processing (NLP) Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  <span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#a9c335\">Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['america', 'america', 'http://gil', 'america']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[\"America\",\"AMERICA\",\"HTTP://gil\",\"AmeriCA\"]\n",
    "lwrwrds = [word.lower() for word in words]\n",
    "lwrwrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alabama', 'Republican', 'Gov', '', 'Kay', 'Ivey', 'signed', 'into', 'law', 'on', 'Monday', 'a', 'bill', '', '', 'legalizing', 'medical', 'marijuana', '', '', '', '', '', 'in', 'the', 'state', '', '']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Alabama Republican Gov. Kay Ivey signed into law on Monday a bill ! legalizing medical marijuana // > in the state?.\"\n",
    "# Split my_string on sentence endings and print the result\n",
    "sentence_endings = r\"[.,!,?,>, //]\"\n",
    "print(re.split(sentence_endings, sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  <span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#b7c335\">Removing HTTP links, URL address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['America']\n",
      "['AMERICA']\n",
      "['']\n",
      "['AmeriCA']\n"
     ]
    }
   ],
   "source": [
    "words=[\"America\",\"AMERICA\",\"http://gil\",\"AmeriCA\"]\n",
    "#Removal of HTTP links/URLs mixed up in any text:\n",
    "for word in words: \n",
    "    cleanword = [re.sub('http://\\S+|https://\\S+','', word)]\n",
    "    print(cleanword)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  <span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#b7c335\">Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/jayanthikishore/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>lemmatized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>connected</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>connection</td>\n",
       "      <td>connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connections</td>\n",
       "      <td>connections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>connects</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word lemmatized_word\n",
       "0       connect         connect\n",
       "1     connected         connect\n",
       "2    connection      connection\n",
       "3   connections     connections\n",
       "4      connects         connect"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# init lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words=[\"connect\",\"connected\",\"connection\",\"connections\",\"connects\"]\n",
    "lemmatized_words=[lemmatizer.lemmatize(word=word,pos='v') for word in words]\n",
    "\n",
    "#Prepare into a data table\n",
    "lemmatizeddf= pd.DataFrame({'original_word': words,'lemmatized_word': lemmatized_words})\n",
    "lemmatizeddf=lemmatizeddf[['original_word','lemmatized_word']]\n",
    "lemmatizeddf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  <span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#35c359\">Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>connected</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>connection</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>connections</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>connects</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word stemmed_word\n",
       "0       connect      connect\n",
       "1     connected      connect\n",
       "2    connection      connect\n",
       "3   connections      connect\n",
       "4      connects      connect"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# init stemmer\n",
    "porter_stemmer=PorterStemmer()\n",
    "\n",
    "words=[\"connect\",\"connected\",\"connection\",\"connections\",\"connects\"]\n",
    "\n",
    "stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n",
    "\n",
    "#prepare dataframe\n",
    "stemdf= pd.DataFrame({'original_word': words,'stemmed_word': stemmed_words})\n",
    "stemdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  <span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#6ec335\">Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence =  this is a text full of content and we need to clean it up\n",
      "sentence with stop words removed=  R R R text full R content R R R R clean R R\n"
     ]
    }
   ],
   "source": [
    "stopwords=['this','that','and','a','we','it','to','is','of','up','need','the','there']\n",
    "text=\"this is a text full of content and we need to clean it up\"\n",
    "\n",
    "words=text.split(\" \")\n",
    "shortlisted_words=[]\n",
    "\n",
    "#remove stop words\n",
    "for w in words:\n",
    "    if w not in stopwords:\n",
    "        shortlisted_words.append(w)\n",
    "    else:\n",
    "        shortlisted_words.append(\"R\")\n",
    "\n",
    "print(\"original sentence = \",text)    \n",
    "print(\"sentence with stop words removed= \",' '.join(shortlisted_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  <span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#35c39d\">Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_word</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..trouble..</td>\n",
       "      <td>..trouble..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble&lt;</td>\n",
       "      <td>trouble&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trouble!</td>\n",
       "      <td>trouble!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;a&gt;trouble&lt;/a&gt;</td>\n",
       "      <td>&lt;a&gt;trouble&lt;/a&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.trouble</td>\n",
       "      <td>1.troubl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         raw_word    stemmed_word\n",
       "0     ..trouble..     ..trouble..\n",
       "1        trouble<        trouble<\n",
       "2        trouble!        trouble!\n",
       "3  <a>trouble</a>  <a>trouble</a>\n",
       "4       1.trouble        1.troubl"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter_stemmer=PorterStemmer()\n",
    "\n",
    "raw_words=[\"..trouble..\",\"trouble<\",\"trouble!\",\"<a>trouble</a>\",'1.trouble']\n",
    "stemmed_words=[porter_stemmer.stem(word=word) for word in raw_words]\n",
    "\n",
    "#concating nating original and output into a table\n",
    "stemdf= pd.DataFrame({'raw_word': raw_words,'stemmed_word': stemmed_words})\n",
    "stemdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  <span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#35bcc3\">Split into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'certainly', 'a', 'sensitive', '?', 'and', 'emotional', 'issue', 'and', 'something', 'that', 'is', 'continually', '>', 'being', 'studied', ',', 'Ivey', 'said', 'in', 'a', 'statement', '.', 'On', 'the', 'state', 'level', ',', 'we', 'have', 'had', 'a', 'study', 'group', 'that', 'has', 'looked', 'closely', 'at', 'this', 'issue', ',', 'and', 'I', 'am', 'interested', 'in', 'the', 'potential', 'good', 'medical', 'cannabis', 'can', 'have', 'for', 'those', 'with', 'chronic', 'illnesses', 'or', 'what', 'it', 'can', 'do', 'to', 'improve', 'the', 'quality', 'of', 'life', 'of', 'those', 'in', 'their', 'final', 'days', '!', '!', '!', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence= \"This is certainly a sensitive ? and emotional issue and something that is continually > being studied, Ivey said in a statement. On the state level, we have had a study group that has looked closely at this issue, and I am interested in the potential good medical cannabis can have for those with chronic illnesses or what it can do to improve the quality of life of those in their final days! !!.\"\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(sentence)\n",
    "print(tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  <span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#35a2c3\">Filterout punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'certainly', 'a', 'sensitive', 'and', 'emotional', 'issue', 'and', 'something', 'that', 'is', 'continually', 'being', 'studied', 'Ivey', 'said', 'in', 'a', 'statement', 'On', 'the', 'state', 'level', 'we', 'have', 'had', 'a', 'study', 'group', 'that', 'has', 'looked', 'closely', 'at', 'this', 'issue', 'and', 'I', 'am', 'interested', 'in', 'the', 'potential', 'good', 'medical', 'cannabis', 'can', 'have', 'for', 'those', 'with', 'chronic', 'illnesses', 'or', 'what', 'it', 'can', 'do', 'to', 'improve', 'the', 'quality', 'of', 'life', 'of', 'those', 'in', 'their', 'final', 'days']\n"
     ]
    }
   ],
   "source": [
    "# remove all tokens that are not alphabetic\n",
    "words = [word for word in tokens if word.isalpha()]\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  <span style=\"font-family: Arial; font-weight:bold;font-size:1.0em;color:#3570c3\">Filterout stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'certainly', 'sensitive', 'emotional', 'issue', 'something', 'continually', 'studied', 'Ivey', 'said', 'statement', 'On', 'state', 'level', 'study', 'group', 'looked', 'closely', 'issue', 'I', 'interested', 'potential', 'good', 'medical', 'cannabis', 'chronic', 'illnesses', 'improve', 'quality', 'life', 'final', 'days']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# print(stop_words)\n",
    "\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
